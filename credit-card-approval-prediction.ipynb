{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Credit Card Approval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_plot(x, dataframe, ax=None, **kwargs):\n",
    "    if len(kwargs)==1 and kwargs['mode']=='horizontal':\n",
    "        sns.countplot(y=x, data=dataframe, ax=ax, order=dataframe[x].value_counts().index)\n",
    "    else:\n",
    "        sns.countplot(x=x, data=dataframe, ax=ax, order=dataframe[x].value_counts().index)\n",
    "    plt.box(False)\n",
    "    return None\n",
    "\n",
    "    \n",
    "def pie_plot(df_col, fig_size, title):\n",
    "    fig, ax = plt.subplots(figsize=fig_size)\n",
    "    ax.pie(df_col.values, autopct='%1.2f%%', shadow=False, startangle=90)\n",
    "    ax.axis('equal')\n",
    "    plt.legend(labels=df_col.index, bbox_to_anchor=(1.05, 1))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "\n",
    "def stacked_vBar_plot(dataframe, value, index, column, xlabel, fig_size, scale='linear', with_percent=True):\n",
    "    \n",
    "    df_1 = dataframe.pivot_table(values=[value], index=[index], columns=[column], aggfunc=len, margins=True)\n",
    "    df_1_percent = df_1.div(df_1.iloc[:,-1], axis=0).mul(100, axis=0).round(2)\n",
    "    df_2_percent = df_1_percent.iloc[:, :-1].drop('All')\n",
    "    \n",
    "    columns = df_2_percent.columns.levels[1].tolist()\n",
    "    columns.remove('All')\n",
    "    \n",
    "    ax = df_2_percent.plot.bar(stacked=True)\n",
    "    ax.figure.set_size_inches(fig_size)\n",
    "    ax.grid(False)\n",
    "    plt.legend(labels=columns, bbox_to_anchor=(1.05, 1), title='NPS Type')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('%GT Count of NPS_Type')\n",
    "    \n",
    "    if with_percent:\n",
    "        # Add this loop to add the annotations\n",
    "        for p in ax.patches:\n",
    "            width, height = p.get_width(), p.get_height()\n",
    "            x, y = p.get_xy() \n",
    "            ax.annotate('{:.2f}%'.format(height), (x + width/8, y + height/2))\n",
    "    plt.box(False)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "\n",
    "def pdf_distribution_plots(df, features, target):\n",
    "    nrow = int((len(features)/3) + len(features)%3)\n",
    "    \n",
    "    t0 = df.loc[df[target] == 0]\n",
    "    t1 = df.loc[df[target] == 1]\n",
    "\n",
    "    sns.set_style('whitegrid')\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "    for indx, feature in enumerate(features):\n",
    "        ax = fig.add_subplot(nrow, 3, indx+1)\n",
    "        sns.kdeplot(t0[feature], label=\"0\", legend=True)\n",
    "        sns.kdeplot(t1[feature], label=\"1\", legend=True)\n",
    "        ax.set_ylabel('Density', fontsize=12)\n",
    "        ax.set_xlabel(feature, fontsize=12)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "        ax.legend(loc='best')\n",
    "    \n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None,wspace= 0.3, hspace=0.5)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "\n",
    "def clipping(dataframe, num_cols):\n",
    "    df_copy = dataframe.copy()\n",
    "    for col in num_cols:\n",
    "        p25 = np.percentile(df_copy[col], 25)\n",
    "        p75 = np.percentile(df_copy[col], 75)\n",
    "        iqr = p75 - p25\n",
    "        df_copy[col] = np.clip(df_copy[col], a_min=np.floor((p25 - 1.5*iqr)), a_max=np.ceil((p75 + 1.5*iqr)))\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def get_category(df, col, binsnum, labels, qcut = False):\n",
    "    if qcut:\n",
    "        localdf = pd.qcut(df[col], q = binsnum, labels = labels) # quantile cut\n",
    "    else:\n",
    "        localdf = pd.cut(df[col], bins = binsnum, labels = labels) # equal-length cut\n",
    "        \n",
    "    localdf = pd.DataFrame(localdf)\n",
    "    name = col + '_CAT'\n",
    "    localdf[name] = localdf[col]\n",
    "    df = df.join(localdf[name])\n",
    "    df[name] = df[name].astype(object)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_df = pd.read_csv('./data/application_record.csv')\n",
    "\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df = pd.read_csv('./data/credit_record.csv')\n",
    "\n",
    "credit_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate applications\n",
    "application_df = application_df.drop_duplicates(subset='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target label creation - target=1 (high risk) iff there is at least one month where user is late on payments by 30 days or more\n",
    "credit_df['target_status'] = np.where((credit_df['STATUS']=='0')|(credit_df['STATUS']=='C')|(credit_df['STATUS']=='X'), 0, 1)\n",
    "target_df=pd.DataFrame(credit_df.groupby(['ID'])['target_status'].agg(max)).reset_index()\n",
    "\n",
    "# Merge target label to application dataset\n",
    "merged_df = pd.merge(application_df, target_df, how='inner', on='ID')\n",
    "merged_df['target_status'] = merged_df['target_status'].astype(\"category\")\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "merged_df['OCCUPATION_TYPE'].fillna(value='Other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive new features\n",
    "merged_df = get_category(merged_df, col='AMT_INCOME_TOTAL', binsnum=3, labels=[\"low\",\"medium\", \"high\"], qcut = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation\n",
    "merged_df['DAYS_BIRTH'] = -1 * merged_df['DAYS_BIRTH']\n",
    "merged_df['DAYS_EMPLOYED'] = -1 * merged_df['DAYS_EMPLOYED']\n",
    "merged_df['DAYS_EMPLOYED'] = np.where((merged_df['DAYS_EMPLOYED']<=0), 0, merged_df['DAYS_EMPLOYED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
    "                'NAME_HOUSING_TYPE', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'AMT_INCOME_TOTAL_CAT']\n",
    "\n",
    "dropped_cat_features = ['FLAG_MOBIL']\n",
    "\n",
    "num_features = ['AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_FAM_MEMBERS']\n",
    "\n",
    "dropped_num_features = ['CNT_CHILDREN']\n",
    "\n",
    "all_features = num_features + cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers\n",
    "merged_df = clipping(dataframe=merged_df, num_cols=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[num_features].describe().applymap('{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[cat_features] = merged_df[cat_features].astype(\"category\")\n",
    "merged_df[cat_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode categorical features\n",
    "to_label_encode = ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']\n",
    "\n",
    "for feature in to_label_encode:\n",
    "    labelencoder = LabelEncoder()\n",
    "    merged_df[feature] = labelencoder.fit_transform(merged_df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encode CO features - NAME_EDUCATION_TYPE, AMT_INCOME_TOTAL_CAT\n",
    "edu_type_oe = OrdinalEncoder(categories=[['Lower secondary', 'Secondary / secondary special', 'Incomplete higher', 'Higher education', 'Academic degree']], dtype='int32')\n",
    "merged_df['NAME_EDUCATION_TYPE'] = edu_type_oe.fit_transform(np.array(merged_df['NAME_EDUCATION_TYPE']).reshape(-1,1))\n",
    "\n",
    "incm_cat_oe = OrdinalEncoder(categories=[[\"low\",\"medium\", \"high\"]], dtype='int32')\n",
    "merged_df[\"AMT_INCOME_TOTAL_CAT\"] = incm_cat_oe.fit_transform(np.array(merged_df['AMT_INCOME_TOTAL_CAT']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode nominal features\n",
    "to_onehot_encode = ['NAME_INCOME_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE']\n",
    "\n",
    "merged_df = pd.get_dummies(data=merged_df, prefix=['inc_typ', 'fam_sta', 'hou_typ', 'occu_typ'], columns=to_onehot_encode)\n",
    "\n",
    "print(\"Dataset shape: {}\".format(merged_df.shape))\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data types\n",
    "merged_df['FLAG_WORK_PHONE'] = merged_df['FLAG_WORK_PHONE'].astype('uint8')\n",
    "merged_df['FLAG_PHONE'] = merged_df['FLAG_PHONE'].astype('uint8')\n",
    "merged_df['FLAG_EMAIL'] = merged_df['FLAG_EMAIL'].astype('uint8')\n",
    "merged_df['target_status'] = merged_df['target_status'].astype('uint8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create independent and dependent variables\n",
    "X = merged_df.drop(columns=['ID', 'FLAG_MOBIL', 'CNT_CHILDREN', 'target_status'])\n",
    "y = merged_df['target_status']\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1295, shuffle=True, stratify=y)\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features\n",
    "scaler = StandardScaler().fit(X_train[num_features])\n",
    "\n",
    "X_train[num_features] = scaler.transform(X_train[num_features])\n",
    "X_test[num_features] = scaler.transform(X_test[num_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_clf = GaussianNB()\n",
    "\n",
    "gnb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "\n",
    "grid_values = {\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-4, 4, 20)\n",
    "}\n",
    "\n",
    "grid_lr_clf = GridSearchCV(lr_clf, param_grid=grid_values, scoring='recall', cv=5, n_jobs=4, verbose=10)\n",
    "\n",
    "grid_lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Grid best parameter: ', grid_lr_clf.best_params_)\n",
    "print('Grid best score (recall): ', grid_lr_clf.best_score_)\n",
    "print('\\nBest Estimator: ', grid_lr_clf.best_estimator_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbours (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(weights='uniform', n_jobs=1)\n",
    "\n",
    "grid_values = {\n",
    "    'n_neighbors': [1, 2, 3, 5, 7, 9, 10]\n",
    "}\n",
    "\n",
    "grid_knn_clf = GridSearchCV(knn_clf, param_grid=grid_values, scoring='recall', cv=5, n_jobs=4, verbose=10)\n",
    "\n",
    "grid_knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Grid best parameter: ', grid_knn_clf.best_params_)\n",
    "print('Grid best score (recall): ', grid_knn_clf.best_score_)\n",
    "print('\\nBest Estimator: ', grid_knn_clf.best_estimator_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=1295)\n",
    "\n",
    "grid_values = {\n",
    "    'max_depth' : [2, 3, 5, 7, 9],\n",
    "    'min_samples_split' : [2, 3, 4, 5, 6],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "grid_dt_clf = GridSearchCV(dt_clf, param_grid=grid_values, scoring='recall', cv=5, n_jobs=4, verbose=10)\n",
    "\n",
    "grid_dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Grid best parameter: ', grid_dt_clf.best_params_)\n",
    "print('Grid best score (recall): ', grid_dt_clf.best_score_)\n",
    "print('\\nBest Estimator: ', grid_dt_clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fig, _ = plt.subplots(nrows=1, ncols=1, figsize=(100,50), dpi=300)\n",
    "tree.plot_tree(\n",
    "    grid_dt_clf.best_estimator_,\n",
    "    feature_names=all_features,\n",
    "    filled=True\n",
    ")\n",
    "\n",
    "fig.savefig('./outputs/dt_clf.png', transparent=False)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(gamma='scale')\n",
    "\n",
    "grid_values = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "grid_svm_clf = GridSearchCV(svm_clf, param_grid=grid_values, scoring='recall', cv=5, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid_svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Grid best parameter: ', grid_svm_clf.best_params_)\n",
    "print('Grid best score (recall): ', grid_svm_clf.best_score_)\n",
    "print('\\nBest Estimator: ', grid_svm_clf.best_estimator_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gnb_clf\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Training set\n",
    "print(\"------------------------Training Set------------------------\")\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "print(\"Training Set Accuracy: {:.4f}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "print(\"Training Set Precision: {:.4f}\".format(precision_score(y_train, y_train_pred)))\n",
    "print(\"Training Set Recall: {:.4f}\".format(recall_score(y_train, y_train_pred)))\n",
    "print(\"Training Set f1: {:.4f}\".format(f1_score(y_train, y_train_pred)))\n",
    "\n",
    "\n",
    "# Test set\n",
    "print(\"\\n--------------------------Test Set--------------------------\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"Test Set Accuracy: {:.4f}\".format(accuracy_score(y_test, y_test_pred)))\n",
    "print(\"Test Set Precision: {:.4f}\".format(precision_score(y_test, y_test_pred)))\n",
    "print(\"Test Set Recall: {:.4f}\".format(recall_score(y_test, y_test_pred)))\n",
    "print(\"Test Set f1: {:.4f}\".format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_lr_clf.best_estimator_\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Training set\n",
    "print(\"------------------------Training Set------------------------\")\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "print(\"Training Set Accuracy: {:.4f}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "print(\"Training Set Precision: {:.4f}\".format(precision_score(y_train, y_train_pred)))\n",
    "print(\"Training Set Recall: {:.4f}\".format(recall_score(y_train, y_train_pred)))\n",
    "print(\"Training Set f1: {:.4f}\".format(f1_score(y_train, y_train_pred)))\n",
    "\n",
    "\n",
    "# Test set\n",
    "print(\"\\n--------------------------Test Set--------------------------\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"Test Set Accuracy: {:.4f}\".format(accuracy_score(y_test, y_test_pred)))\n",
    "print(\"Test Set Precision: {:.4f}\".format(precision_score(y_test, y_test_pred)))\n",
    "print(\"Test Set Recall: {:.4f}\".format(recall_score(y_test, y_test_pred)))\n",
    "print(\"Test Set f1: {:.4f}\".format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_knn_clf.best_estimator_\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Training set\n",
    "print(\"------------------------Training Set------------------------\")\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "print(\"Training Set Accuracy: {:.4f}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "print(\"Training Set Precision: {:.4f}\".format(precision_score(y_train, y_train_pred)))\n",
    "print(\"Training Set Recall: {:.4f}\".format(recall_score(y_train, y_train_pred)))\n",
    "print(\"Training Set f1: {:.4f}\".format(f1_score(y_train, y_train_pred)))\n",
    "\n",
    "\n",
    "# Test set\n",
    "print(\"\\n--------------------------Test Set--------------------------\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"Test Set Accuracy: {:.4f}\".format(accuracy_score(y_test, y_test_pred)))\n",
    "print(\"Test Set Precision: {:.4f}\".format(precision_score(y_test, y_test_pred)))\n",
    "print(\"Test Set Recall: {:.4f}\".format(recall_score(y_test, y_test_pred)))\n",
    "print(\"Test Set f1: {:.4f}\".format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_dt_clf.best_estimator_\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Training set\n",
    "print(\"------------------------Training Set------------------------\")\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "print(\"Training Set Accuracy: {:.4f}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "print(\"Training Set Precision: {:.4f}\".format(precision_score(y_train, y_train_pred)))\n",
    "print(\"Training Set Recall: {:.4f}\".format(recall_score(y_train, y_train_pred)))\n",
    "print(\"Training Set f1: {:.4f}\".format(f1_score(y_train, y_train_pred)))\n",
    "\n",
    "\n",
    "# Test set\n",
    "print(\"\\n--------------------------Test Set--------------------------\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"Test Set Accuracy: {:.4f}\".format(accuracy_score(y_test, y_test_pred)))\n",
    "print(\"Test Set Precision: {:.4f}\".format(precision_score(y_test, y_test_pred)))\n",
    "print(\"Test Set Recall: {:.4f}\".format(recall_score(y_test, y_test_pred)))\n",
    "print(\"Test Set f1: {:.4f}\".format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_svm_clf.best_estimator_\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Training set\n",
    "print(\"------------------------Training Set------------------------\")\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "print(\"Training Set Accuracy: {:.4f}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "print(\"Training Set Precision: {:.4f}\".format(precision_score(y_train, y_train_pred)))\n",
    "print(\"Training Set Recall: {:.4f}\".format(recall_score(y_train, y_train_pred)))\n",
    "print(\"Training Set f1: {:.4f}\".format(f1_score(y_train, y_train_pred)))\n",
    "\n",
    "\n",
    "# Test set\n",
    "print(\"\\n--------------------------Test Set--------------------------\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"Test Set Accuracy: {:.4f}\".format(accuracy_score(y_test, y_test_pred)))\n",
    "print(\"Test Set Precision: {:.4f}\".format(precision_score(y_test, y_test_pred)))\n",
    "print(\"Test Set Recall: {:.4f}\".format(recall_score(y_test, y_test_pred)))\n",
    "print(\"Test Set f1: {:.4f}\".format(f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_CLBW_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
